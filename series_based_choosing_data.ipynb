{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Choosing data for SeriesBasedCesnetDataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "from datetime import datetime\n",
                "\n",
                "from cesnet_tszoo.utils.enums import AgreggationType, SourceType, TimeFormat, DatasetType\n",
                "from cesnet_tszoo.datasets import CESNET_TimeSeries24\n",
                "from cesnet_tszoo.configs import SeriesBasedConfig # Series based dataset MUST use SeriesBasedConfig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setting logger"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format=\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preparing dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:46,430][cesnet_dataset][INFO] - Dataset is series-based. Use cesnet_tszoo.configs.SeriesBasedConfig\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Dataset details:\n",
                        "\n",
                        "    AgreggationType.AGG_1_HOUR\n",
                        "        Time indices: range(0, 6717)\n",
                        "        Datetime: (datetime.datetime(2023, 10, 9, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 7, 14, 21, 0, tzinfo=datetime.timezone.utc))\n",
                        "\n",
                        "    SourceType.INSTITUTION_SUBNETS\n",
                        "        Time series indices: [0 1 2 3 4 ... 543 544 545 546 547], Length=548; use 'get_available_ts_indices' for full list\n",
                        "        Features with default values: {'n_flows': 0, 'n_packets': 0, 'n_bytes': 0, 'tcp_udp_ratio_packets': 0.5, 'tcp_udp_ratio_bytes': 0.5, 'dir_ratio_packets': 0.5, 'dir_ratio_bytes': 0.5, 'avg_duration': 0, 'avg_ttl': 0, 'sum_n_dest_asn': 0, 'avg_n_dest_asn': 0, 'std_n_dest_asn': 0, 'sum_n_dest_ports': 0, 'avg_n_dest_ports': 0, 'std_n_dest_ports': 0, 'sum_n_dest_ip': 0, 'avg_n_dest_ip': 0, 'std_n_dest_ip': 0}\n",
                        "        \n",
                        "        Additional data: ['ids_relationship', 'weekends_and_holidays']\n",
                        "        \n"
                    ]
                }
            ],
            "source": [
                "series_based_dataset = CESNET_TimeSeries24.get_dataset(data_root=\"/some_directory/\", source_type=SourceType.INSTITUTION_SUBNETS, aggregation=AgreggationType.AGG_1_HOUR, dataset_type=DatasetType.SERIES_BASED, display_details=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting time period"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- `time_period` sets time period for all sets (used time series)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period as \"all\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as a whole time period from dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:46,435][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:46,437][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-28 18:01:46,448][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 794.45it/s]\n",
                        "[2025-11-28 18:01:47,158][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:47,158][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 6718)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=\"all\")\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with time indices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as range of time indices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:47,173][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:47,174][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-28 18:01:47,185][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1924.31it/s]\n",
                        "[2025-11-28 18:01:47,490][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:47,490][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 2000)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=range(0, 2000))\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with datetime"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series with tuple of datetime objects.\n",
                "- Datetime objects are expected to be of UTC."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:47,501][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:47,503][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-28 18:01:47,508][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 2246.63it/s]\n",
                        "[2025-11-28 18:01:47,773][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:47,774][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 767)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=(datetime(2023, 10, 9, 0), datetime(2023, 11, 9, 23)))\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with percentage"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as a percentage of whole time period from dataset.\n",
                "- Always starts from first time.\n",
                "- Must be: 0 < `time_period` <= 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:47,833][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:47,835][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-28 18:01:47,844][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1544.30it/s]\n",
                        "[2025-11-28 18:01:48,219][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:48,219][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Creating train/val/test sets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets how many time series will be in each set.\n",
                "- You can leave any set value set as None.\n",
                "- Can use `nan_threshold` to set how many nan values will be tolerated.\n",
                "    - `nan_threshold` = 1.0, means that time series can be completely empty.\n",
                "    - is applied after sets."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with count of time series"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time series in set with count.\n",
                "- Each set will contain unique time series.\n",
                "- Count must be greater than zero.\n",
                "- Total sum of time series in sets must be smaller than number of time series in dataset.\n",
                "- Is affected by `random_state`.\n",
                "    - When `random_state` is set, sets will contain same time series."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:48,228][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:48,235][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-28 18:01:48,236][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1269.38it/s]\n",
                        "[2025-11-28 18:01:48,290][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1202.55it/s]\n",
                        "[2025-11-28 18:01:48,317][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1175.83it/s]\n",
                        "[2025-11-28 18:01:48,328][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:48,328][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [210 172  48  83 264 ... 512  49   8 196  29], Length=54\n",
                        "        Val time series IDS: [159 333  87 224 457 ... 372 205 491 446 347], Length=25\n",
                        "        Test time series IDS [410  12 478 212  30 398 281 161 307 349], Length=10\n",
                        "        All time series IDS [210 172  48  83 264 ... 398 281 161 307 349], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, random_state=None, nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with percentage of time series in dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time series in set with percentage of time series in dataset.\n",
                "- Each set will contain unique time series.\n",
                "- Percentage must be greater than 0.\n",
                "- Total sum of set percentages must be smaller or equal to 1.0.\n",
                "- Is affected by `random_state`.\n",
                "    - When `random_state` is set, sets will contain same time series."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:48,336][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:48,343][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-28 18:01:48,344][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 274/274 [00:00<00:00, 1440.58it/s]\n",
                        "[2025-11-28 18:01:48,555][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 109/109 [00:00<00:00, 1335.50it/s]\n",
                        "[2025-11-28 18:01:48,647][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1077.07it/s]\n",
                        "[2025-11-28 18:01:48,702][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:48,702][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [547 449  25 187 348 ... 224 249 493  91 207], Length=274\n",
                        "        Val time series IDS: [ 13 121 519 258 255 ... 110 368 298 245 342], Length=109\n",
                        "        Test time series IDS [372  92 331  10 428 ... 109 235 545 400  82], Length=54\n",
                        "        All time series IDS [547 449  25 187 348 ... 109 235 545 400  82], Length=437\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=0.5, val_ts=0.2, test_ts=0.1, random_state=None, nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with specific time series indices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Each set must have unique time series"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:48,718][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:48,723][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-28 18:01:48,724][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1109.72it/s]\n",
                        "[2025-11-28 18:01:48,738][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1250.54it/s]\n",
                        "[2025-11-28 18:01:48,747][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1250.69it/s]\n",
                        "[2025-11-28 18:01:48,753][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:48,753][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [0 1 2 3 4], Length=5\n",
                        "        Val time series IDS: [5 6 7 8 9], Length=5\n",
                        "        Test time series IDS [10 11 12 13 14], Length=5\n",
                        "        All time series IDS [0 1 2 3 4 ... 10 11 12 13 14], Length=15\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=[0,1,2,3,4], val_ts=[5,6,7,8,9], test_ts=[10,11,12,13,14], nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Affects which features will be returned when loading data.\n",
                "- Setting `include_time` as True will add time to features that return when loading data.\n",
                "- Setting `include_ts_id` as True will add time series id to features that return when loading data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting features to take as \"all\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:48,758][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:48,764][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-28 18:01:48,765][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1207.15it/s]\n",
                        "[2025-11-28 18:01:48,821][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1135.63it/s]\n",
                        "[2025-11-28 18:01:48,850][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1175.90it/s]\n",
                        "[2025-11-28 18:01:48,860][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:48,861][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [371 434 441 448 259 ... 130 303 363 191 218], Length=54\n",
                        "        Val time series IDS: [374 104 425 296  50 ... 297 542  37 106 131], Length=25\n",
                        "        Test time series IDS [547 156 184 401 173   5 360  55  59  18], Length=10\n",
                        "        All time series IDS [371 434 441 448 259 ...   5 360  55  59  18], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=\"all\")\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting features via list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:48,869][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:48,875][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-28 18:01:48,876][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1511.87it/s]\n",
                        "[2025-11-28 18:01:48,923][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1315.11it/s]\n",
                        "[2025-11-28 18:01:48,948][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1332.33it/s]\n",
                        "[2025-11-28 18:01:48,959][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:48,959][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [ 95  71 508 256 471 ... 255  82  19 320 314], Length=54\n",
                        "        Val time series IDS: [442 515 229 175 293 ... 113 449 425  63 134], Length=25\n",
                        "        Test time series IDS [496 297 153   3 201 196  49  35 514 504], Length=10\n",
                        "        All time series IDS [ 95  71 508 256 471 ... 196  49  35 514 504], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=[\"n_flows\", \"n_packets\"])\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Including time and time series id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:48,966][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:48,973][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-28 18:01:48,973][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1348.84it/s]\n",
                        "[2025-11-28 18:01:49,026][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1245.15it/s]\n",
                        "[2025-11-28 18:01:49,053][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1332.58it/s]\n",
                        "[2025-11-28 18:01:49,064][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:49,065][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [285 205  69 339  22 ... 102 476 287  17 163], Length=54\n",
                        "        Val time series IDS: [309 231 537 289 544 ... 261 363 503 192  75], Length=25\n",
                        "        Test time series IDS [294 161 390 179 128 431 337 426 229 540], Length=10\n",
                        "        All time series IDS [285 205  69 339  22 ... 431 337 426 229 540], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=[\"n_flows\", \"n_packets\"], include_time=True, include_ts_id=True, time_format=TimeFormat.ID_TIME)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting all set"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### All set when other sets are None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- All set will contain all time series from dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:49,072][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:49,074][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-28 18:01:49,085][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1623.52it/s]\n",
                        "[2025-11-28 18:01:49,440][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:49,440][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=None, val_ts=None, test_ts=None)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### All set when at least one other set is not None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- All set will contain all time series that were set by other sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-28 18:01:49,450][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-28 18:01:49,457][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-28 18:01:49,457][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1250.28it/s]\n",
                        "[2025-11-28 18:01:49,513][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1211.76it/s]\n",
                        "[2025-11-28 18:01:49,540][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1246.97it/s]\n",
                        "[2025-11-28 18:01:49,550][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-28 18:01:49,550][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [358  79 191 542  10 ... 141 268 432 363 178], Length=54\n",
                        "        Val time series IDS: [340  93 269 131 143 ... 507  37 453  34 386], Length=25\n",
                        "        Test time series IDS [354 411 525 479 247 229 456 445 461 538], Length=10\n",
                        "        All time series IDS [358  79 191 542  10 ... 229 456 445 461 538], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.1.0\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

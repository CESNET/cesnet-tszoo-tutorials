{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Choosing data for SeriesBasedCesnetDataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "from datetime import datetime\n",
                "\n",
                "from cesnet_tszoo.utils.enums import AgreggationType, SourceType, TimeFormat, DatasetType\n",
                "from cesnet_tszoo.datasets import CESNET_TimeSeries24\n",
                "from cesnet_tszoo.configs import SeriesBasedConfig # Series based dataset MUST use SeriesBasedConfig"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setting logger"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format=\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preparing dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:28,510][cesnet_dataset][INFO] - Dataset is series-based. Use cesnet_tszoo.configs.SeriesBasedConfig\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Dataset details:\n",
                        "\n",
                        "    AgreggationType.AGG_1_HOUR\n",
                        "        Time indices: range(0, 6717)\n",
                        "        Datetime: (datetime.datetime(2023, 10, 9, 0, 0, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 7, 14, 21, 0, tzinfo=datetime.timezone.utc))\n",
                        "\n",
                        "    SourceType.INSTITUTION_SUBNETS\n",
                        "        Time series indices: [0 1 2 3 4 ... 543 544 545 546 547], Length=548; use 'get_available_ts_indices' for full list\n",
                        "        Features with default values: {'n_flows': 0, 'n_packets': 0, 'n_bytes': 0, 'tcp_udp_ratio_packets': 0.5, 'tcp_udp_ratio_bytes': 0.5, 'dir_ratio_packets': 0.5, 'dir_ratio_bytes': 0.5, 'avg_duration': 0, 'avg_ttl': 0, 'sum_n_dest_asn': 0, 'avg_n_dest_asn': 0, 'std_n_dest_asn': 0, 'sum_n_dest_ports': 0, 'avg_n_dest_ports': 0, 'std_n_dest_ports': 0, 'sum_n_dest_ip': 0, 'avg_n_dest_ip': 0, 'std_n_dest_ip': 0}\n",
                        "        \n",
                        "        Additional data: ['ids_relationship', 'weekends_and_holidays']\n",
                        "        \n"
                    ]
                }
            ],
            "source": [
                "series_based_dataset = CESNET_TimeSeries24.get_dataset(data_root=\"/some_directory/\", source_type=SourceType.INSTITUTION_SUBNETS, aggregation=AgreggationType.AGG_1_HOUR, dataset_type=DatasetType.SERIES_BASED, display_details=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting time period"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- `time_period` sets time period for all sets (used time series)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period as \"all\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as a whole time period from dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:28,515][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:28,516][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-14 18:37:28,528][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 803.38it/s]\n",
                        "[2025-11-14 18:37:29,230][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:29,230][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 6718)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=\"all\")\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with time indices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as range of time indices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:29,240][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:29,242][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-14 18:37:29,250][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 2008.01it/s]\n",
                        "[2025-11-14 18:37:29,542][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:29,542][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 2000)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=range(0, 2000))\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with datetime"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series with tuple of datetime objects.\n",
                "- Datetime objects are expected to be of UTC."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:29,552][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:29,554][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-14 18:37:29,558][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 2320.18it/s]\n",
                        "[2025-11-14 18:37:29,812][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:29,812][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 767)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=(datetime(2023, 10, 9, 0), datetime(2023, 11, 9, 23)))\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting time period with percentage"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time period for time series as a percentage of whole time period from dataset.\n",
                "- Always starts from first time.\n",
                "- Must be: 0 < `time_period` <= 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:29,875][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:29,877][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-14 18:37:29,885][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1535.19it/s]\n",
                        "[2025-11-14 18:37:30,261][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:30,262][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Creating train/val/test sets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets how many time series will be in each set.\n",
                "- You can leave any set value set as None.\n",
                "- Can use `nan_threshold` to set how many nan values will be tolerated.\n",
                "    - `nan_threshold` = 1.0, means that time series can be completely empty.\n",
                "    - is applied after sets."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with count of time series"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time series in set with count.\n",
                "- Each set will contain unique time series.\n",
                "- Count must be greater than zero.\n",
                "- Total sum of time series in sets must be smaller than number of time series in dataset.\n",
                "- Is affected by `random_state`.\n",
                "    - When `random_state` is set, sets will contain same time series."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:30,273][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:30,279][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-14 18:37:30,280][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1294.18it/s]\n",
                        "[2025-11-14 18:37:30,335][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1189.77it/s]\n",
                        "[2025-11-14 18:37:30,364][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1175.43it/s]\n",
                        "[2025-11-14 18:37:30,375][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:30,375][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [218 450  10 529 373 ... 312  68   3 121 264], Length=54\n",
                        "        Val time series IDS: [236 495 536 424 142 ... 530 174 345  96 331], Length=25\n",
                        "        Test time series IDS [144 411 492 214 406  74 192  89 240 378], Length=10\n",
                        "        All time series IDS [218 450  10 529 373 ...  74 192  89 240 378], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, random_state=None, nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with percentage of time series in dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sets time series in set with percentage of time series in dataset.\n",
                "- Each set will contain unique time series.\n",
                "- Percentage must be greater than 0.\n",
                "- Total sum of set percentages must be smaller or equal to 1.0.\n",
                "- Is affected by `random_state`.\n",
                "    - When `random_state` is set, sets will contain same time series."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:30,384][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:30,390][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-14 18:37:30,391][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 274/274 [00:00<00:00, 1396.70it/s]\n",
                        "[2025-11-14 18:37:30,607][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 109/109 [00:00<00:00, 1280.10it/s]\n",
                        "[2025-11-14 18:37:30,704][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1284.50it/s]\n",
                        "[2025-11-14 18:37:30,752][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:30,752][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [421 230 461 116 309 ...   4 393  34 219 436], Length=274\n",
                        "        Val time series IDS: [484  89 115 218 135 ... 251  63 176 201 226], Length=109\n",
                        "        Test time series IDS [417  97 390  99 362 ... 143 327 237 158 170], Length=54\n",
                        "        All time series IDS [421 230 461 116 309 ... 143 327 237 158 170], Length=437\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=0.5, val_ts=0.2, test_ts=0.1, random_state=None, nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting sets with specific time series indices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Each set must have unique time series"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:30,765][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:30,771][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-14 18:37:30,771][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1250.39it/s]\n",
                        "[2025-11-14 18:37:30,787][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1427.51it/s]\n",
                        "[2025-11-14 18:37:30,794][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 5/5 [00:00<00:00, 1250.17it/s]\n",
                        "[2025-11-14 18:37:30,800][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:30,800][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [0 1 2 3 4], Length=5\n",
                        "        Val time series IDS: [5 6 7 8 9], Length=5\n",
                        "        Test time series IDS [10 11 12 13 14], Length=5\n",
                        "        All time series IDS [0 1 2 3 4 ... 10 11 12 13 14], Length=15\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=[0,1,2,3,4], val_ts=[5,6,7,8,9], test_ts=[10,11,12,13,14], nan_threshold=1.0)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Affects which features will be returned when loading data.\n",
                "- Setting `include_time` as True will add time to features that return when loading data.\n",
                "- Setting `include_ts_id` as True will add time series id to features that return when loading data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting features to take as \"all\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:30,806][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:30,812][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-14 18:37:30,812][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1300.18it/s]\n",
                        "[2025-11-14 18:37:30,865][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1105.80it/s]\n",
                        "[2025-11-14 18:37:30,895][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1175.04it/s]\n",
                        "[2025-11-14 18:37:30,908][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:30,908][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [435 482 162 475  64 ... 472  30 347 322 121], Length=54\n",
                        "        Val time series IDS: [279 335 359 276 200 ...  58 538 273 403 292], Length=25\n",
                        "        Test time series IDS [  2  83 493 303 297 285 170 220 507 439], Length=10\n",
                        "        All time series IDS [435 482 162 475  64 ... 285 170 220 507 439], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=\"all\")\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Setting features via list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:30,916][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:30,922][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-14 18:37:30,923][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1254.37it/s]\n",
                        "[2025-11-14 18:37:30,977][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1386.88it/s]\n",
                        "[2025-11-14 18:37:31,002][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1243.35it/s]\n",
                        "[2025-11-14 18:37:31,013][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:31,013][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [174 290 461  84 464 ... 189 183 332 369 107], Length=54\n",
                        "        Val time series IDS: [484 393 253 436 238 ...  79 156 298 382 524], Length=25\n",
                        "        Test time series IDS [127 214 317 207 489 385 227 434 202 500], Length=10\n",
                        "        All time series IDS [174 290 461  84 464 ... 385 227 434 202 500], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=[\"n_flows\", \"n_packets\"])\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Including time and time series id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:31,020][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:31,026][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-14 18:37:31,027][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1520.39it/s]\n",
                        "[2025-11-14 18:37:31,074][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1387.68it/s]\n",
                        "[2025-11-14 18:37:31,099][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1396.19it/s]\n",
                        "[2025-11-14 18:37:31,107][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:31,108][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [261 428 436 217 525 ... 514 515 494 346 141], Length=54\n",
                        "        Val time series IDS: [526 537 200 387 240 ... 455 512 314  19 232], Length=25\n",
                        "        Test time series IDS [407 225 393 115 460 378 532 379 355 474], Length=10\n",
                        "        All time series IDS [261 428 436 217 525 ... 378 532 379 355 474], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10, features_to_take=[\"n_flows\", \"n_packets\"], include_time=True, include_ts_id=True, time_format=TimeFormat.ID_TIME)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Selecting all set"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### All set when other sets are None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- All set will contain all time series from dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:31,116][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:31,117][series_config][INFO] - Using all time series for all_ts because train_ts, val_ts, and test_ts are all set to None.\n",
                        "[2025-11-14 18:37:31,125][cesnet_dataset][INFO] - Updating config for all set.\n",
                        "100%|██████████| 548/548 [00:00<00:00, 1606.63it/s]\n",
                        "[2025-11-14 18:37:31,486][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:31,487][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: None\n",
                        "        Val time series IDS: None\n",
                        "        Test time series IDS None\n",
                        "        All time series IDS [0 1 2 3 4 ... 543 544 545 546 547], Length=548\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=None, val_ts=None, test_ts=None)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### All set when at least one other set is not None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- All set will contain all time series that were set by other sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:37:31,496][series_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:37:31,502][cesnet_dataset][INFO] - Updating config for train set and fitting values.\n",
                        "[2025-11-14 18:37:31,503][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 54/54 [00:00<00:00, 1173.10it/s]\n",
                        "[2025-11-14 18:37:31,560][cesnet_dataset][INFO] - Updating config for val set.\n",
                        "100%|██████████| 25/25 [00:00<00:00, 1189.71it/s]\n",
                        "[2025-11-14 18:37:31,587][cesnet_dataset][INFO] - Updating config for test set.\n",
                        "100%|██████████| 10/10 [00:00<00:00, 1176.26it/s]\n",
                        "[2025-11-14 18:37:31,599][cesnet_dataset][INFO] - Dataset initialization complete. Configuration updated.\n",
                        "[2025-11-14 18:37:31,599][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details:\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_1_HOUR\n",
                        "    Source: SourceType.INSTITUTION_SUBNETS\n",
                        "\n",
                        "    Time series\n",
                        "        Train time series IDS: [333 264  78 442 166 ... 374  37 124 327 483], Length=54\n",
                        "        Val time series IDS: [429 171 410 449 260 ...  64 345 435 143 350], Length=25\n",
                        "        Test time series IDS [200 423 546 472 488 323 349  42 253 426], Length=10\n",
                        "        All time series IDS [333 264  78 442 166 ... 323 349  42 253 426], Length=89\n",
                        "    Time periods\n",
                        "        Time period: range(0, 3359)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets', 'n_bytes', 'sum_n_dest_asn', 'avg_n_dest_asn', 'std_n_dest_asn', 'sum_n_dest_ports', 'avg_n_dest_ports', 'std_n_dest_ports', 'sum_n_dest_ip', 'avg_n_dest_ip', 'std_n_dest_ip', 'tcp_udp_ratio_packets', 'tcp_udp_ratio_bytes', 'dir_ratio_packets', 'dir_ratio_bytes', 'avg_duration', 'avg_ttl']\n",
                        "        Default values: [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.5 0.5 0.  0. ]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Fillers         \n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type (train set): NoAnomalyHandler   \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "        Init worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['filling_gaps', 'handling_anomalies', 'transforming']\n",
                        "        Nan threshold: 1.0\n",
                        "        Random state: None\n",
                        "        Train dataloader order: DataloaderOrder.SEQUENTIAL\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = SeriesBasedConfig(time_period=0.5, train_ts=54, val_ts=25, test_ts=10)\n",
                "series_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

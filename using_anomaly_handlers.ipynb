{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Using anomaly handlers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook will only use TimeBasedCesnetDataset, but all methods work almost the same way for other dataset types."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import logging\n",
                "\n",
                "from cesnet_tszoo.utils.enums import AgreggationType, SourceType, AnomalyHandlerType, DatasetType\n",
                "from cesnet_tszoo.datasets import CESNET_TimeSeries24\n",
                "from cesnet_tszoo.configs import TimeBasedConfig # Time based dataset MUST use TimeBasedConfig\n",
                "\n",
                "from cesnet_tszoo.utils.anomaly_handler import AnomalyHandler # For creating custom Anomaly handler"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setting logger"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format=\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preparing dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:46:16,238][cesnet_dataset][INFO] - Dataset is time-based. Use cesnet_tszoo.configs.TimeBasedConfig\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Dataset details:\n",
                        "\n",
                        "    AgreggationType.AGG_10_MINUTES\n",
                        "        Time indices: range(0, 40297)\n",
                        "        Datetime: (datetime.datetime(2023, 10, 9, 0, 3, 49, tzinfo=datetime.timezone.utc), datetime.datetime(2024, 7, 14, 21, 50, 52, tzinfo=datetime.timezone.utc))\n",
                        "\n",
                        "    SourceType.IP_ADDRESSES_SAMPLE\n",
                        "        Time series indices: [ 11  20 101 103 118 ... 2003134 2008461 2011839 2022235 2044888], Length=1000; use 'get_available_ts_indices' for full list\n",
                        "        Features with default values: {'n_flows': 0, 'n_packets': 0, 'n_bytes': 0, 'n_dest_ip': 0, 'n_dest_asn': 0, 'n_dest_ports': 0, 'tcp_udp_ratio_packets': 0.5, 'tcp_udp_ratio_bytes': 0.5, 'dir_ratio_packets': 0.5, 'dir_ratio_bytes': 0.5, 'avg_duration': 0, 'avg_ttl': 0}\n",
                        "        \n",
                        "        Additional data: ['ids_relationship', 'weekends_and_holidays']\n",
                        "        \n"
                    ]
                }
            ],
            "source": [
                "time_based_dataset = CESNET_TimeSeries24.get_dataset(data_root=\"/some_directory/\", source_type=SourceType.IP_ADDRESSES_SAMPLE, aggregation=AgreggationType.AGG_10_MINUTES, dataset_type=DatasetType.TIME_BASED, display_details=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Anomaly handlers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Anomaly handlers are implemented as class.\n",
                "    - You can create your own or use built-in one.\n",
                "- Anomaly handler is applied before `default_values` and fillers took care of missing values (default preprocess order).\n",
                "- Every time series in train set has its own anomaly handler instance.\n",
                "- Anomaly handler must implement `fit` and `transform_anomalies`.\n",
                "- To use anomaly handler, train set must be implemented.\n",
                "- Anomaly handler will only be used on train set.\n",
                "- You can change used anomaly handler later with `update_dataset_config_and_initialize` or `apply_anomaly_handler`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Built-in"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<AnomalyHandlerType.INTERQUARTILE_RANGE: 'interquartile_range'>"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Options\n",
                "\n",
                "## Supported\n",
                "AnomalyHandlerType.Z_SCORE\n",
                "AnomalyHandlerType.INTERQUARTILE_RANGE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:46:16,251][time_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:46:16,337][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:16,338][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 500/500 [00:00<00:00, 843.60it/s]\n",
                        "[2025-11-14 18:46:17,011][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_10_MINUTES\n",
                        "    Source: SourceType.IP_ADDRESSES_SAMPLE\n",
                        "\n",
                        "    Time series\n",
                        "        Time series IDS: [182151  10158  65072  10196 338309 ... 175742 659213  11188  73422 483796], Length=53\n",
                        "    Time periods\n",
                        "        Train time periods: range(0, 20149)\n",
                        "        Val time periods: range(20149, 28208)\n",
                        "        Test time periods: range(28208, 32237)\n",
                        "        All time periods: range(0, 32237)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Sliding window\n",
                        "        Sliding window size: None\n",
                        "        Sliding window prediction size: None\n",
                        "        Sliding window step size: 1\n",
                        "        Set shared size: 0\n",
                        "    Fillers\n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type: ZScore        \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Init worker count: 4\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['handling_anomalies', 'filling_gaps', 'transforming']\n",
                        "        Nan threshold: 0.5\n",
                        "        Random state: 1500\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = TimeBasedConfig(ts_ids=500, train_time_period=0.5, val_time_period=0.2, test_time_period=0.1, features_to_take=['n_flows', 'n_packets'],\n",
                "                           handle_anomalies_with=AnomalyHandlerType.Z_SCORE, nan_threshold=0.5, random_state=1500)\n",
                "time_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id_ip</th>\n",
                            "      <th>id_time</th>\n",
                            "      <th>n_flows</th>\n",
                            "      <th>n_packets</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>7.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>5.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>8.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>3.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>6.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>12.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      id_ip  id_time  n_flows  n_packets\n",
                            "0  182151.0      0.0      7.0        7.0\n",
                            "1  182151.0      1.0      4.0        4.0\n",
                            "2  182151.0      2.0      4.0        4.0\n",
                            "3  182151.0      3.0      5.0        5.0\n",
                            "4  182151.0      4.0      8.0        8.0\n",
                            "5  182151.0      5.0      3.0        3.0\n",
                            "6  182151.0      6.0      6.0        6.0\n",
                            "7  182151.0      7.0      4.0        4.0\n",
                            "8  182151.0      8.0      9.0       12.0\n",
                            "9  182151.0      9.0      0.0        0.0"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "time_based_dataset.get_train_df(workers=0).head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Or later with:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:46:17,220][cesnet_dataset][INFO] - Re-initialization is required.\n",
                        "[2025-11-14 18:46:17,302][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:17,303][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 53/53 [00:00<00:00, 198.96it/s]\n",
                        "[2025-11-14 18:46:17,576][cesnet_dataset][INFO] - Config initialized successfully.\n",
                        "[2025-11-14 18:46:17,577][cesnet_dataset][INFO] - Configuration has been changed successfuly.\n",
                        "[2025-11-14 18:46:17,579][cesnet_dataset][INFO] - Re-initialization is required.\n",
                        "[2025-11-14 18:46:17,660][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:17,661][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 53/53 [00:00<00:00, 203.51it/s]\n",
                        "[2025-11-14 18:46:17,929][cesnet_dataset][INFO] - Config initialized successfully.\n",
                        "[2025-11-14 18:46:17,931][cesnet_dataset][INFO] - Configuration has been changed successfuly.\n",
                        "[2025-11-14 18:46:17,931][cesnet_dataset][INFO] - Anomaly handler has been changed successfuly.\n"
                    ]
                }
            ],
            "source": [
                "time_based_dataset.update_dataset_config_and_initialize(handle_anomalies_with=AnomalyHandlerType.Z_SCORE, workers=0)\n",
                "# Or\n",
                "time_based_dataset.apply_anomaly_handler(handle_anomalies_with=AnomalyHandlerType.Z_SCORE, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Custom"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- You can create your own custom anomaly handler. It is recommended to derive from AnomalyHandler base class.\n",
                "- Take care that custom anomaly handler should be imported from other file when while using this library in Jupyter notebook. When not importing from other file/s use workers == 0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CustomAnomalyHandler(AnomalyHandler):\n",
                "    def __init__(self):\n",
                "        self.lower_bound = None\n",
                "        self.upper_bound = None\n",
                "        self.iqr = None\n",
                "\n",
                "    def fit(self, data: np.ndarray) -> None:\n",
                "        q25, q75 = np.percentile(data, [25, 75], axis=0)\n",
                "        self.iqr = q75 - q25\n",
                "\n",
                "        self.lower_bound = q25 - 1.5 * self.iqr\n",
                "        self.upper_bound = q75 + 1.5 * self.iqr\n",
                "\n",
                "    def transform_anomalies(self, data: np.ndarray) -> np.ndarray:\n",
                "        mask_lower_outliers = data < self.lower_bound\n",
                "        mask_upper_outliers = data > self.upper_bound\n",
                "\n",
                "        data[mask_lower_outliers] = np.take(self.lower_bound, np.where(mask_lower_outliers)[1])\n",
                "        data[mask_upper_outliers] = np.take(self.upper_bound, np.where(mask_upper_outliers)[1])       "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:46:17,942][time_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:46:18,024][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:18,025][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 500/500 [00:00<00:00, 917.18it/s]\n",
                        "[2025-11-14 18:46:18,592][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_10_MINUTES\n",
                        "    Source: SourceType.IP_ADDRESSES_SAMPLE\n",
                        "\n",
                        "    Time series\n",
                        "        Time series IDS: [182151  10158  65072  10196 338309 ... 175742 659213  11188  73422 483796], Length=53\n",
                        "    Time periods\n",
                        "        Train time periods: range(0, 20149)\n",
                        "        Val time periods: range(20149, 28208)\n",
                        "        Test time periods: range(28208, 32237)\n",
                        "        All time periods: range(0, 32237)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Sliding window\n",
                        "        Sliding window size: None\n",
                        "        Sliding window prediction size: None\n",
                        "        Sliding window step size: 1\n",
                        "        Set shared size: 0\n",
                        "    Fillers\n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type: CustomAnomalyHandler (Custom)        \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Init worker count: 4\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['handling_anomalies', 'filling_gaps', 'transforming']\n",
                        "        Nan threshold: 0.5\n",
                        "        Random state: 1500\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = TimeBasedConfig(ts_ids=500, train_time_period=0.5, val_time_period=0.2, test_time_period=0.1, features_to_take=['n_flows', 'n_packets'],\n",
                "                           handle_anomalies_with=CustomAnomalyHandler, nan_threshold=0.5, random_state=1500)\n",
                "time_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id_ip</th>\n",
                            "      <th>id_time</th>\n",
                            "      <th>n_flows</th>\n",
                            "      <th>n_packets</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>7.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>5.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>8.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>3.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>6.0</td>\n",
                            "      <td>6.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>4.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>12.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>182151.0</td>\n",
                            "      <td>9.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      id_ip  id_time  n_flows  n_packets\n",
                            "0  182151.0      0.0      7.0        7.0\n",
                            "1  182151.0      1.0      4.0        4.0\n",
                            "2  182151.0      2.0      4.0        4.0\n",
                            "3  182151.0      3.0      5.0        5.0\n",
                            "4  182151.0      4.0      8.0        8.0\n",
                            "5  182151.0      5.0      3.0        3.0\n",
                            "6  182151.0      6.0      6.0        6.0\n",
                            "7  182151.0      7.0      4.0        4.0\n",
                            "8  182151.0      8.0      9.0       12.0\n",
                            "9  182151.0      9.0      0.0        0.0"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "time_based_dataset.get_train_df(workers=0).head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Or later with:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:46:18,775][cesnet_dataset][INFO] - Re-initialization is required.\n",
                        "[2025-11-14 18:46:18,859][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:18,859][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 53/53 [00:00<00:00, 229.86it/s]\n",
                        "[2025-11-14 18:46:19,098][cesnet_dataset][INFO] - Config initialized successfully.\n",
                        "[2025-11-14 18:46:19,099][cesnet_dataset][INFO] - Configuration has been changed successfuly.\n",
                        "[2025-11-14 18:46:19,101][cesnet_dataset][INFO] - Re-initialization is required.\n",
                        "[2025-11-14 18:46:19,185][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:19,186][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 53/53 [00:00<00:00, 235.70it/s]\n",
                        "[2025-11-14 18:46:19,417][cesnet_dataset][INFO] - Config initialized successfully.\n",
                        "[2025-11-14 18:46:19,419][cesnet_dataset][INFO] - Configuration has been changed successfuly.\n",
                        "[2025-11-14 18:46:19,420][cesnet_dataset][INFO] - Anomaly handler has been changed successfuly.\n"
                    ]
                }
            ],
            "source": [
                "time_based_dataset.update_dataset_config_and_initialize(handle_anomalies_with=CustomAnomalyHandler, workers=0)\n",
                "# Or\n",
                "time_based_dataset.apply_anomaly_handler(handle_anomalies_with=CustomAnomalyHandler, workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Changing when is anomaly handler applied"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- You can change when is a anomaly handler applied with `preprocess_order` parameter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:46:19,425][time_config][INFO] - Quick validation succeeded.\n",
                        "[2025-11-14 18:46:19,510][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:19,511][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 500/500 [00:00<00:00, 857.68it/s]\n",
                        "[2025-11-14 18:46:20,116][cesnet_dataset][INFO] - Config initialized successfully.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Config Details\n",
                        "    Used for database: CESNET-TimeSeries24\n",
                        "    Aggregation: AgreggationType.AGG_10_MINUTES\n",
                        "    Source: SourceType.IP_ADDRESSES_SAMPLE\n",
                        "\n",
                        "    Time series\n",
                        "        Time series IDS: [182151  10158  65072  10196 338309 ... 175742 659213  11188  73422 483796], Length=53\n",
                        "    Time periods\n",
                        "        Train time periods: range(0, 20149)\n",
                        "        Val time periods: range(20149, 28208)\n",
                        "        Test time periods: range(28208, 32237)\n",
                        "        All time periods: range(0, 32237)\n",
                        "    Features\n",
                        "        Taken features: ['n_flows', 'n_packets']\n",
                        "        Default values: [0. 0.]\n",
                        "        Time series ID included: True\n",
                        "        Time included: True    \n",
                        "        Time format: TimeFormat.ID_TIME\n",
                        "    Sliding window\n",
                        "        Sliding window size: None\n",
                        "        Sliding window prediction size: None\n",
                        "        Sliding window step size: 1\n",
                        "        Set shared size: 0\n",
                        "    Fillers\n",
                        "        Filler type: NoFiller\n",
                        "    Transformers\n",
                        "        Transformer type: NoTransformer\n",
                        "    Anomaly handler\n",
                        "        Anomaly handler type: ZScore        \n",
                        "    Batch sizes\n",
                        "        Train batch size: 32\n",
                        "        Val batch size: 64\n",
                        "        Test batch size: 128\n",
                        "        All batch size: 128\n",
                        "    Default workers\n",
                        "        Init worker count: 4\n",
                        "        Train worker count: 4\n",
                        "        Val worker count: 3\n",
                        "        Test worker count: 2\n",
                        "        All worker count: 4\n",
                        "    Other\n",
                        "        Preprocess order: ['handling_anomalies', 'filling_gaps', 'transforming']\n",
                        "        Nan threshold: 0.5\n",
                        "        Random state: 1500\n",
                        "        Version: 2.0.1\n",
                        "                \n"
                    ]
                }
            ],
            "source": [
                "config = TimeBasedConfig(ts_ids=500, train_time_period=0.5, val_time_period=0.2, test_time_period=0.1, features_to_take=['n_flows', 'n_packets'],\n",
                "                           handle_anomalies_with=AnomalyHandlerType.Z_SCORE, nan_threshold=0.5, random_state=1500, preprocess_order=[\"handling_anomalies\", \"filling_gaps\", \"transforming\"])\n",
                "time_based_dataset.set_dataset_config_and_initialize(config, display_config_details=\"text\", workers=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Or later with:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[2025-11-14 18:46:20,126][cesnet_dataset][INFO] - Re-initialization is required.\n",
                        "[2025-11-14 18:46:20,212][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:20,213][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 53/53 [00:00<00:00, 191.77it/s]\n",
                        "[2025-11-14 18:46:20,496][cesnet_dataset][INFO] - Config initialized successfully.\n",
                        "[2025-11-14 18:46:20,498][cesnet_dataset][INFO] - Configuration has been changed successfuly.\n",
                        "[2025-11-14 18:46:20,500][cesnet_dataset][INFO] - Re-initialization is required.\n",
                        "[2025-11-14 18:46:20,584][cesnet_dataset][INFO] - Updating config on train/val/test/all and selected time series.\n",
                        "[2025-11-14 18:46:20,585][cesnet_dataset][INFO] - Starting fitting cycle 1/1.\n",
                        "100%|██████████| 53/53 [00:00<00:00, 201.72it/s]\n",
                        "[2025-11-14 18:46:20,855][cesnet_dataset][INFO] - Config initialized successfully.\n",
                        "[2025-11-14 18:46:20,906][cesnet_dataset][INFO] - Configuration has been changed successfuly.\n",
                        "[2025-11-14 18:46:20,906][cesnet_dataset][INFO] - Preprocess order has been changed successfuly.\n"
                    ]
                }
            ],
            "source": [
                "time_based_dataset.update_dataset_config_and_initialize(preprocess_order=[\"filling_gaps\", \"handling_anomalies\", \"transforming\"], workers=0)\n",
                "# Or\n",
                "time_based_dataset.set_preprocess_order(preprocess_order=[\"filling_gaps\", \"handling_anomalies\", \"transforming\"], workers=0)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
